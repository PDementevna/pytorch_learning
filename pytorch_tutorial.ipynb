{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pytorch_tutorial.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-2e2d97f4",
   "language": "python",
   "display_name": "PyCharm (pytorch_learning)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    # Change MisterMap to your github account name and make fun\n",
    "    !pip install --upgrade -q git+https://github.com/PDementevna/pytorch_learning.git\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "\n",
    "def notify_start():\n",
    "    output.eval_js('new Audio(\"https://ssl.gstatic.com/dictionary/static/' +\\\n",
    "        'pronunciation/2019-10-21/audio/tr/train_en_us_1.mp3\").play()')\n",
    "    output.eval_js('new Audio(\"https://ssl.gstatic.com/dictionary/static/' +\\\n",
    "        'pronunciation/2019-10-21/audio/st/start_en_us_1.mp3\").play()')\n",
    "\n",
    "def notify_end():\n",
    "    output.eval_js('new Audio(\"https://ssl.gstatic.com/dictionary/static/' +\\\n",
    "        'pronunciation/2019-10-21/audio/tr/train_en_us_1.mp3\").play()')\n",
    "    output.eval_js('new Audio(\"https://ssl.gstatic.com/dictionary/static/' +\\\n",
    "        'pronunciation/2019-10-21/audio/do/done_en_us_1.mp3\").play()')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "MAIN_DIR = '/content/drive/My Drive/dataset'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6j52xeY9WcBp",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch \n",
    "from torchvision import transforms, datasets\n",
    "import torchvision "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HBMykiw9W3CN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHOB7ygRY9bI",
    "colab_type": "text"
   },
   "source": [
    "###Load data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xysZJt5kYOch",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle=True)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8o4jyw6ZPbp",
    "colab_type": "text"
   },
   "source": [
    "###Batch_size: the number of samles which the neural network will get in one run (usually from 8 to 64, regardless to the memory size of the PC)\n",
    "\n",
    "###Shuffle: we need to show to the neural network a variety of data in order to don't have the unexpected result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lDdFu8nAY5bf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "outputId": "3cf1dcbb-5af4-450a-ad48-adf940d6898f"
   },
   "source": [
    "for data in trainset:\n",
    "  print(data)\n",
    "  break"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 9, 0, 8, 4, 7, 7, 3, 5, 4])]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKD_N5ULeGGB",
    "colab_type": "text"
   },
   "source": [
    "In the data variable there is 2 tensors: \n",
    "\n",
    "1) for the image (there are 10 images in batch, so if we want to show first image, we should get access to data[0][0]: 0 - for 1 tensor, and 0 in the tensor)\n",
    "\n",
    "2) for the actual true numbers, so if we want to show first true value correspondent to data[0][0], we need to get access to data[1][0]: 1 - for the 2nd tensor, 0 - in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j2m1kHPgdKvk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "57016cbf-f689-49f3-d45a-d4a81066e708"
   },
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n9Q63heifJy-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import matplotlib.pyplot as plt\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r5LKMK1TfmhY",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "cf2552cb-cde0-4778-c94e-634e38a9bb5d"
   },
   "source": [
    "data[0][0].shape"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqmH2tyrfrgV",
    "colab_type": "text"
   },
   "source": [
    "The shape of the data[0][0] is not convienient one, it has 1 in the first dimension for torch manipulations, therefore we need to squeeze data or use view parameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dbvX8uGjh8w5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "62347caf-0f43-4159-ecfd-329df5c89edb"
   },
   "source": [
    "data[0][0].squeeze().shape"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3eR8_HwfiC6E",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "60bba779-5f31-475f-fb6f-c2d03feae617"
   },
   "source": [
    "data[0][0].view(28,28).shape"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ve4chZt8fPB1",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "outputId": "3874acdb-aed7-42f9-c365-2fdfe0adea8c"
   },
   "source": [
    "plt.imshow(data[0][0].squeeze(), cmap='gray')"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5d295c1c50>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dble3CNvk3gn",
    "colab_type": "text"
   },
   "source": [
    "###We need to be sure that our data is totally ballanced, so we will check how many samles for each number we have in dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B8Znn-G7iLzN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "9bf02fa9-9304-431e-a841-8394159612c9"
   },
   "source": [
    "total = 0\n",
    "counter_dict = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0 , 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
    "\n",
    "for data in trainset:\n",
    "  Xs, ys = data\n",
    "  for y in ys:\n",
    "    counter_dict[int(y)] += 1\n",
    "    total += 1\n",
    "  \n",
    "print(counter_dict)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NXtwptdnkZcf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "outputId": "56599eb8-5c4e-4118-fd41-2d7bfca6e918"
   },
   "source": [
    "for i in counter_dict:\n",
    "  print(f\"{i}: {counter_dict[i]/total*100}\")"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckn5QYZPlJV3",
    "colab_type": "text"
   },
   "source": [
    "####So the data is pretty balanced, we don't need to change something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUmCthxwl-tQ",
    "colab_type": "text"
   },
   "source": [
    "##Let's create neural network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vn7_oTNFkvr3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1smDe3KgmHE3",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "720603d3-17be-4de5-c533-fa0c8239ea4c"
   },
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    # launching the inicialization of parent class nn.Module in next line \n",
    "    super().__init__() \n",
    "\n",
    "    # definition of the fully conected layers (fc)\n",
    "    self.fc1 = nn.Linear(28*28, 64)\n",
    "    # input for the first layer is the flatten image and output can be any number but we stay with 64\n",
    "    # next layer has to take output number from the previous layer, so in our case it's 64. Let's leave 64 for output as well\n",
    "    self.fc2 = nn.Linear(64, 64)\n",
    "    self.fc3 = nn.Linear(64, 64)\n",
    "    # fo the last layer we have 64 as input but in the result we expect 10 classes (because we have 10 numbers: 0 1 2 3 4 5 6 7 8 9 10)\n",
    "    self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    # relu - it's an activation function which is has to be in order to magnitude the output from layers in right way (apply the sigmoid function\n",
    "    # and return the result in range from 0 to 1)\n",
    "    x = F.relu(self.fc2(x))\n",
    "\n",
    "    # here in forward method we can put some logic with operator if (if we need it)\n",
    "\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = self.fc4(x)\n",
    "\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "net\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ba8VUxS-pFk_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X = torch.rand((28, 28))\n",
    "X = X.view(-1,28*28)\n",
    "#  -1 in view method is the hint to the pytorch to fill this dimension by itself, for us it doesn't matter, what is the number is there"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pAwIgbc666ID",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "output = net(X)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eA876Mxa7Ael",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "54adedf3-96ac-4aeb-b608-3f2a6f1a41ba"
   },
   "source": [
    "output"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.2528, -2.2875, -2.3527, -2.3339, -2.3212, -2.3338, -2.1494, -2.4171,\n",
       "         -2.2818, -2.3185]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6mtF9xvT9b0o",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "2f486679-06d8-4387-a2d8-a0873c6eba90"
   },
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "# number of passes through the whole of dataset\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for data in trainset:\n",
    "    # data is a batch of featuresets and labels\n",
    "    X, y = data\n",
    "    # we need to set the gradients to zero because through passing the batches they accumulating\n",
    "    net.zero_grad()\n",
    "    output = net(X.view(-1, 28*28))\n",
    "    \n",
    "    # our true value is a scalar, therefore, we can't use just MSE, instead of it we will use nll_loss\n",
    "    loss = F.nll_loss(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  print(loss)\n",
    "\n"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor(0.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L50L4IkCDOzf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "36f40e6b-db04-4275-be8a-8359028c7ca3"
   },
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  for data in trainset:\n",
    "    X, y = data\n",
    "    output = net(X.view(-1, 784))\n",
    "    for idx, i in enumerate(output):\n",
    "      if torch.argmax(i) == y[idx]:\n",
    "        correct += 1\n",
    "      total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Accuracy:  0.978\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7onpnP8KEv68",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "outputId": "025e6341-71dc-443d-8023-fb2ec39df66e"
   },
   "source": [
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RBWzYZvxFekL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "493f5345-aa35-4af1-feb9-f3e5187ae468"
   },
   "source": [
    "print(torch.argmax(net(X[0].view(-1, 784))[0]))"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor(9, grad_fn=<NotImplemented>)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i598jCiSHWYt",
    "colab_type": "text"
   },
   "source": [
    "#Introduction to the Convolution networks\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Convolution networks are used usually for image tasks but recently CNN outperform recurent NN in sequency type of data.\n",
    "\n",
    "Convolution goal is to locate features. The box is convolutional kernel, it ends up with the number which means the found features. So CNN is just dramatically simplify the image and gets the features from it.\n",
    "\n",
    "\n",
    "\n",
    "![example](https://www.researchgate.net/profile/Konstantin_Pervunin/publication/309487032/figure/fig2/AS:422116370718724@1477651793847/a-Illustration-of-the-operation-principle-of-the-convolution-kernel-convolutional-layer.png)\n",
    "\n",
    "Usually after convolution procedure starts pooling, which is basically finds the maximum number from the kernel and leave it in the cell.\n",
    "The 1st layer of CNN tries to divide your image by easiest parts like corners, edges, curves. Then, the 2nd layer is trying to find the patterns a bit more complex like circles, rectangles and so on. The 3rd searches for combination of circles and rectangles and so on. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F1Hp4mwcFquJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}